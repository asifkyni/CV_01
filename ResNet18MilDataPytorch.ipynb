Model Training and Evaluation Using ResNet18
This code demonstrates how to build, train, validate, and test a ResNet18-based neural network model using PyTorch. It includes:

Model Architecture: A custom Net class that utilizes a pre-trained ResNet18 backbone. The model architecture is modified to include a new fully connected layer for classification.

Data Preprocessing: Image data is processed with transformations including resizing, normalization, and tensor conversion.

Data Loading: Datasets and data loaders are created for training, validation, and testing, using ImageFolder for loading images from directory paths.

Training and Validation: Functions are defined for training and validation, including loss and accuracy calculations. Early stopping is implemented to prevent overfitting based on validation loss.

Testing: A separate function evaluates the model's performance on a test set and computes test accuracy.

Model Management: The script handles model saving and loading. If a pre-trained model is available, it will be loaded; otherwise, a new model will be created and trained.

Optimization: Uses the Adam optimizer and a learning rate scheduler to manage the learning rate based on the validation loss.

Key Constants
IMG_SIZE: Size of the input images (224x224 pixels).
NUM_CLASSES: Number of output classes (10).
NUM_EPOCHS: Number of training epochs (30).
Important Paths
train_data_path, valid_data_path, test_data_path: Paths to the training, validation, and test datasets.{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5df41-33cd-44f1-aa0b-0d0ce0820af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 10\n",
    "NUM_FEATURES = 512  # ResNet18 has 512 features\n",
    "NUM_EPOCHS = 30\n",
    "MODEL_FOLDER_PATH = Path.cwd()  # Use current working directory\n",
    "\n",
    "# Define neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, backbone, features_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        # Resnet Backbone (includes avg pooling layer, takes off last FC layer)\n",
    "        self.features = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        self.out = nn.Linear(features_size, num_classes)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Returns network outputs and the features \"\"\"\n",
    "        # put images through ResNet backbone\n",
    "        img_features = self.features(inputs)\n",
    "        img_features = torch.flatten(img_features, start_dim=1)\n",
    "        outputs = self.out(img_features)\n",
    "        return outputs\n",
    "\n",
    "# Load or create the model\n",
    "model_path = MODEL_FOLDER_PATH / f\"model_resnet18_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pt\"\n",
    "if model_path.exists():\n",
    "    model = torch.load(model_path, map_location='cpu')  # Load model to CPU\n",
    "    model.eval()\n",
    "else:\n",
    "    # Create a new model if it doesn't exist\n",
    "    model = Net(resnet18(pretrained=True), NUM_FEATURES, NUM_CLASSES)\n",
    "\n",
    "# Define data preprocessing transformation\n",
    "train_mean = [0.485, 0.456, 0.406]\n",
    "train_std = [0.229, 0.224, 0.225]\n",
    "img_normalize = transforms.Normalize(mean=train_mean, std=train_std)\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        img_normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define data paths\n",
    "train_data_path = \"/mnt/d/FY2023/DataSets/milVehs/dataset/train\"\n",
    "valid_data_path = \"/mnt/d/FY2023/DataSets/milVehs/dataset/validation\"\n",
    "test_data_path = \"/mnt/d/FY2023/DataSets/milVehs/dataset/test\"\n",
    "\n",
    "# Define dataset and dataloader for training, validation, and testing\n",
    "train_dataset = ImageFolder(train_data_path, transform=transform)\n",
    "valid_dataset = ImageFolder(valid_data_path, transform=transform)\n",
    "test_dataset = ImageFolder(test_data_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define optimizer, loss function, and learning rate scheduler\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Define training loop function\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "# Define validation loop function\n",
    "def validate(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    valid_loss = running_loss / len(valid_loader)\n",
    "    valid_accuracy = 100 * correct / total\n",
    "    return valid_loss, valid_accuracy\n",
    "\n",
    "# Training loop\n",
    "best_valid_loss = float('inf')\n",
    "patience = 5\n",
    "counter = 0\n",
    "for epoch in range(NUM_EPOCHS):  # Train for 30 epochs\n",
    "    # Train the model\n",
    "    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion)\n",
    "    \n",
    "    # Validate the model\n",
    "    valid_loss, valid_accuracy = validate(model, valid_loader, criterion)\n",
    "    \n",
    "    # Check if validation loss has decreased\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        \n",
    "    # Print training and validation metrics\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.2f}%\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Test the model (You have not defined test() function, please define it)\n",
    "# test_accuracy = test(model, test_loader)\n",
    "# print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Save the model as a .pt file\n",
    "torch.save(model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7558cd3-0d10-4b5f-a49a-335186073d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a .pt file\n",
    "torch.save(model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6ad4f-4319-4d26-bc9c-06317daa836a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00189648-4a1e-4512-9feb-f2d8069d539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 30\n",
    "MODEL_FOLDER_PATH = Path.cwd()  # Use current working directory\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# Load or create the model\n",
    "model_path = MODEL_FOLDER_PATH / f\"model_resnet18_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pt\"\n",
    "if model_path.exists():\n",
    "    model = torch.load(model_path, map_location=DEVICE)\n",
    "    model.eval()\n",
    "else:\n",
    "    model = resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "\n",
    "# Define data preprocessing transformation\n",
    "train_mean = [0.485, 0.456, 0.406]\n",
    "train_std = [0.229, 0.224, 0.225]\n",
    "img_normalize = transforms.Normalize(mean=train_mean, std=train_std)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    img_normalize,\n",
    "])\n",
    "\n",
    "# Define data paths\n",
    "train_data_path = \"/mnt/d/FY2023/DataSets/milVehs/dataset/train\"\n",
    "valid_data_path = \"/mnt/d/FY2023/DataSets/milVehs/dataset/validation\"\n",
    "test_data_path = \"/mnt/d/FY2023/DataSets/milVehs/dataset/test\"\n",
    "\n",
    "# Define dataset and dataloader for training, validation, and testing\n",
    "train_dataset = ImageFolder(train_data_path, transform=transform)\n",
    "valid_dataset = ImageFolder(valid_data_path, transform=transform)\n",
    "test_dataset = ImageFolder(test_data_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define optimizer, loss function, and learning rate scheduler\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Define training loop function\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "# Define validation loop function\n",
    "def validate(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    valid_loss = running_loss / len(valid_loader)\n",
    "    valid_accuracy = 100 * correct / total\n",
    "    return valid_loss, valid_accuracy\n",
    "\n",
    "# Training loop\n",
    "best_valid_loss = float('inf')\n",
    "patience = 5\n",
    "counter = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_accuracy = validate(model, valid_loader, criterion)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.2f}%\")\n",
    "    \n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Test the model\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_accuracy = 100 * correct / total\n",
    "    return test_accuracy\n",
    "\n",
    "test_accuracy = test(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bcdc6f-aae6-4d74-ab8c-d76d9a5b49d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
